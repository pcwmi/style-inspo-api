2025-12-29 13:16:04 - Streaming Spec Failure - Lesson: Created a "streaming" spec that only set static progress messages, not true token streaming. User tested and found it useless (stare at "Creating outfit 1 of 3" for 20s). Root cause: optimized for easy implementation over solving the problem. Prevention: (1) Walk through UX second-by-second before handing off specs, (2) Validate spec solves problem during the slow part, (3) Don't label something "MVP" when it's barely useful, (4) Run first-principles time studies before assuming. We then validated OpenAI streaming actually delivers tokens in real-time, ran time study showing outfits generate sequentially (~4s each), and tested interleaved JSON prompt which delivers first outfit ~4s faster.
